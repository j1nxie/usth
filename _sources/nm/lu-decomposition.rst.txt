LU decomposition
================

.. _eigenvalues and eigenvectors:

Eigenvalues and eigenvectors
----------------------------

A homogeneous linear algebraic system has a right-hand side equal to zero.

.. math::

   [A][x] = 0

Eigenvalue problems in engineering are typically of the below general form, with
:math:`\lambda` being the *eigenvalue*:

.. math::

   [[A] - \lambda [I]]\{x\} = 0

For non-trivial solutions to be possible, the determinant of the matrix must
equal zero.

.. math::

   |[A] - \lambda [I]| = 0

Expanding the above determinant gives a polynomial in :math:`\lambda`, called
the *characteristic polynomial*. The roots of the polynomial are the solutions
for the *eigenvalues*.

.. _lu decomposition:

LU Decomposition
----------------

In simple terms, LU decomposition is another way of solving a system, breaking
down the original matrix into two triangular matrices, *lower* and *upper*
(hence, **LU** decomposition).

.. _lu definition:

Formal definition
~~~~~~~~~~~~~~~~~

LU decomposition (where "LU" stands for "lower upper", also known as *LU
factorization*) factors a matrix as a product of a *lower triangular matrix*
:math:`[L]` and an *upper triangular matrix* :math:`[U]`.

.. math::

   \begin{aligned}
      & [A]{x} = {b} \\
      & \downarrow \\
      & [A] = [L][U] \\
   \end{aligned}

.. _lu steps:

Steps in LU factorization
~~~~~~~~~~~~~~~~~~~~~~~~~

**Step 1**: LU factorization:

:math:`[A]` is factorized (or "decomposed") into *lower* :math:`[L]` and *upper*
:math:`[U]` triangular matrices.

.. math::

   [A] = [L][U]

**Step 2**: Substitution step:

:math:`[L]` and :math:`[U]` are used to determine a solution :math:`{x}` for a
right-hand side :math:`{b}`. This step consists of two smaller steps:

- Generate an intermediate vector :math:`{d}` by forward substitution.
- Substitute the result into equation which can be solved using backward
  subsitution for :math:`{x}`.

.. _decomposing into lu:

Decomposing matrix A into L and U
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. math::

   [A] = [L][U]
   = \begin{bmatrix}
      1 & 0 & 0 \\
      l_{21} & 1 & 0 \\ 
      l_{31} & l_{32} & 1 \\
     \end{bmatrix}
   = \begin{bmatrix}
      u_{11} & u_{12} & u_{13} \\
      0 & u_{22} & u_{23} \\
      0 & 0 & u_{33} \\
     \end{bmatrix}

- :math:`[U]` is the same as the coefficient matrix at the end of forward
  elimination.
- :math:`[L]` is obtained using the *multipliers* that were used in forward
  elimination.

.. _finding inverse:

Finding the inverse of a square matrix
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The inverse :math:`[B]` of a square matrix :math:`[A]` is defined as:

.. math::
   
    [A][B] = [I] = [B][A]

To find the inverse of a square matrix using LU decomposition, we start with
assuming the first column of :math:`[B]` to be :math:`[b_{11} \ b_{12} \ \ldots
\ b_{n1}]^T`.

Using this and the definition of matrix multiplication, we obtain the first
column of :math:`[B]` as:

.. math::

   [A]
    \begin{bmatrix}
      b_{11} \\
      b_{21} \\
      \ldots \\
      b_{n1} \\
   \end{bmatrix}
   = \begin{bmatrix}
      1 \\
      0 \\
      \ldots \\
      0 \\
     \end{bmatrix}

Similarly, we also obtain the second column of :math:`[B]` as:

.. math::

   [A]
   \begin{bmatrix}
      b_{12} \\
      b_{22} \\
      \ldots \\
      b_{n2} \\
   \end{bmatrix}
   = \begin{bmatrix}
      0 \\
      1 \\
      \ldots \\
      0 \\
     \end{bmatrix}

The remaining columns can be found in the same manner as above.

.. _lu with pivoting:

LU decomposition with pivoting
------------------------------

Partial pivoting is also necessary to obtain reliable solutions with LU
factorizations. One way to do this involves using a *permutation* matrix, using
the following steps.

**Step 1**: Elimination:

LU factorization with pivoting of a matrix :math:`[A]` can be represented as:

.. math::

   [P][A] = [L][U]

:math:`[U]` is generated by elimination with partial pivoting, while storing the
multiplier factors in :math:`[L]` and employing the permutation matrix
:math:`[P]` to keep track of row switches.

**Step 2**: Forward substitution:

:math:`[L]` and :math:`[P]` are used to perform elimination with pivot on
:math:`{b}` in order to generate the intermediate right-hand-side vector
:math:`{d}`.

.. math::

   [L]{d} = [P]{b}

**Step 3**: Back substitution:

Final solution is generated in the same fashion as Gauss elimination.

.. math::

   [U]{x} = {d}

.. note::

   I very much feel like everyone should give the slide on this section a read,
   especially on the examples. Please also try to do the examples by yourself,
   using these techniques, and you'll understand them much better than reading
   all of the above theory.
